##为什么ruby中的数组可以无限push元素？
ruby中的数组是一链表的结构存在的
##fork()
###(1)fork()的定义
fork()函数是Unix中派生新进程的唯一方法，调用一次fork()方法，该方法会返回两次。一次是在调用进程(也就是派生出的子进程的父进程)中返回一次，返回值是新派生的进程的进程ID。一次是在子进程中返回，返回值是0，代表当前进程为子进程。如果返回值为-1的话，则代表在派生新进程的过程中出错。
###(2)fork()的实质过程
父进程中在调用fork()派生新进程，实际上相当于创建了进程的一个拷贝；即在fork()之前的进程拥有的资源会被复制到新的进程中去。网络服务器在处理并发请求时，也可以采取这种派生新进程的方式: 父进程调用accept()后调用fork()来处理每一个连接。那么，所接受的已连接的套接口随后就在父子进程中共享。通常来说，子进程会在这连接套接口中读和写操作，父进程则关闭这个已连的套接口(可以参考:http://blog.csdn.net/moxiaomomo/article/details/6791763)
###(3)fork()的用法
fork()有两个典型用法：(1)一个进程进行自身的复制，这样每个副本可以独立的完成具体的操作，在多核处理器中可以并行处理数据。这也是网络服务器的其中一个典型用途，多进程处理多连接请求。 (2)一个进程想执行另一个程序。比如一个软件包含了两个程序，主程序想调起另一个程序的话，它就可以先调用fork来创建一个自身的拷贝，然后通过exec函数来替换成将要运行的新程序。

##http与https在安全性上的区别
http协议传输的数据都是明文未加密的，传输过程中存在数据被截获修改的可能；
HTTPS在传输数据之前需要客户端（浏览器）与服务端（网站）之间进行一次握手，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL协议不仅仅是一套加密传输的协议，更是一件经过艺术家精心设计的艺术品，TLS/SSL中使用了非对称加密，对称加密以及HASH算法。握手过程的简单描述如下：
1.浏览器将自己支持的一套加密规则发送给网站。
2.网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。
3.获得网站证书之后浏览器要做以下工作：
a) 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。
b) 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。
c) 使用约定好的HASH计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。
4.网站接收浏览器发来的数据之后要做以下的操作：
a) 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。
b) 使用密码加密一段握手消息，发送给浏览器。
5.浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。
这里浏览器与网站互相发送加密的握手消息并验证，目的是为了保证双方都获得了一致的密码，并且可以正常的加密解密数据，为后续真正数据的传输做一次测试。另外，HTTPS一般使用的加密与HASH算法如下：
非对称加密算法：RSA，DSA/DSS
对称加密算法：AES，RC4，3DES
HASH算法：MD5，SHA1，SHA256
其中非对称加密算法用于在握手过程中加密生成的密码，对称加密算法用于对真正传输的数据进行加密，而HASH算法用于验证数据的完整性。由于浏览器生成的密码是整个数据加密的关键，因此在传输的时候使用了非对称加密算法对其加密。非对称加密算法会生成公钥和私钥，公钥只能用于加密数据，因此可以随意传输，而网站的私钥用于对数据进行解密，所以网站都会非常小心的保管自己的私钥，防止泄漏。
TLS握手过程中如果有任何错误，都会使加密连接断开，从而阻止了隐私信息的传输。正是由于HTTPS非常的安全，攻击者无法从中找到下手的地方，于是更多的是采用了假证书的手法来欺骗客户端，从而获取明文的信息，但是这些手段都可以被识别出来，我将在后续的文章进行讲述。不过2010年还是有安全专家发现了TLS 1.0协议处理的一个漏洞：http://www.theregister.co.uk/2011/09/19/beast_exploits_paypal_ssl/，实际上这种称为BEAST的攻击方式早在2002年就已经被安全专家发现，只是没有公开而已。目前微软和Google已经对此漏洞进行了修复。见：http://support.microsoft.com/kb/2643584/en-us https://src.chromium.org/viewvc/chrome?view=rev&revision=90643

##unicorn的worker
unicorn设置unicorn

一个worker_processes同一时间只能处理一个请求，所以想要处理更多的并发就需要配置足够的worker_processes，但是由此产生的副作用是内存占用就多了。

一个worker_processes占用了将近60m内存（根据你使用的gem数量和种类而定），MySQL占用了150m左右，所以我只开了3个worker_processes。

总的内存使用：

(1 master + 3 worker_processes) x 60m + 150m = 390m

剩余的留给操作系统。

你可以根据你的实际情况进行调整。

unicorn设置unicorn的worker_processes和nginx的worker_processes的设置的关系

nginx的worker_processes 一般设置为cpu核心数相同即可。 
worker_connection这个参数是限制每个worker_processes最大能处理的连接数 (包含客户端到nginx的链接，nginx到后端的链接，等等)。 
此参数大小还受制于操作系统 open file 大小限制。

所以nginx并发处理能力=worker_processes x worker_connection

##数据库的隔离级别
（零）没有并发控制

存在的问题：更新遗失。 
解决办法就是下面的“可读取未确认”。

（一）可读取未确认（Read uncommitted）

写事务阻止其他写事务，避免了更新遗失。但是没有阻止其他读事务。 
存在的问题：脏读。即读取到不正确的数据，因为另一个事务可能还没提交最终数据，这个读事务就读取了中途的数据，这个数据可能是不正确的。 
解决办法就是下面的“可读取确认”。

（二）可读取确认（Read committed）

写事务会阻止其他读写事务。读事务不会阻止其他任何事务。 
存在的问题：不可重复读。即在一次事务之间，进行了两次读取，但是结果不一样，可能第一次id为1的人叫“李三”，第二次读id为1的人就叫了“李四”。因为读取操作不会阻止其他事务。 
解决办法就是下面的“可重复读”。

（三）可重复读（Repeatable read）

读事务会阻止其他写事务，但是不会阻止其他读事务。 
存在的问题：幻读。可重复读阻止的写事务包括update和delete（只给存在的表加上了锁），但是不包括insert（新行不存在，所以没有办法加锁），所以一个事务第一次读取可能读取到了10条记录，但是第二次可能读取到11条，这就是幻读。 
解决办法就是下面的“串行化”。

（四）可串行化（Serializable）

读加共享锁，写加排他锁。这样读取事务可以并发，但是读写，写写事务之间都是互斥的，基本上就是一个个执行事务，所以叫串行化。
